데이터 분석의 시작은 __데이터수집__

Data Crawling
:	데이터 수집(정식으로 데이터를 가져오는 것이 아님)

OAuth
:	웹에서 데이터를 가져올때 인증받는 것

API방식
:	정식으로 데이터를 받아오는 것



###데이터 저장방식	(sql -> nosql)

###Hadoop -> spark로 변하는 추세 (데이터 분석 툴)
>Hadoop은 자바, spark는 다양한 언어지원

map reduce 알고리즘
:	웹에서 몇 번 쓰였는지 찾는 알고리즘 ?

HBR
:	Havard Bussniss review (유명한 일간지?)

Big Data를 써야하는 이유
:	돈이 되는가


---

robots.txt 
:	사이트의 루트에 위치하며 사이트에서 검색 엔진 크롤러가 액세스하지 않기를 바라는 부분을 표시합니다. 파일에서는 로봇 배제 표준 프로토콜의 명령을 사용하여 섹션별, 웹 크롤러 종류별(모바일 크롤러, 데스크톱 크롤러 등)로 사이트에 대한 액세스 권한을 표시합니다.

---
Anaconda 다운후
프로젝트디렉토리에서 Jupyter notebook 실행
mac에서는 Anaconda Navigator 실행후 노트북실행

